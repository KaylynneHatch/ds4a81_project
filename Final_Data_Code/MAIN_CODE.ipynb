{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import glob2\n",
    "import seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_security = pd.read_csv('/Users/kayh/Documents/DS4A/team_81_project/Cleaned Datasets/cleaned_fa_data.csv')\n",
    "\n",
    "#Drop unnamed column\n",
    "food_security = food_security.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#Replace state abbreviations with state names\n",
    "states = {'AK': 'Alaska',\n",
    "    'AL': 'Alabama',\n",
    "    'AR': 'Arkansas',\n",
    "    'AZ': 'Arizona',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DC': 'District of Columbia',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'IA': 'Iowa',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MD': 'Maryland',\n",
    "    'ME': 'Maine',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MO': 'Missouri',\n",
    "    'MS': 'Mississippi',\n",
    "    'MT': 'Montana',\n",
    "    'NA': 'National',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'NE': 'Nebraska',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NV': 'Nevada',\n",
    "    'NY': 'New York',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VA': 'Virginia',\n",
    "    'VT': 'Vermont',\n",
    "    'WA': 'Washington',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WV': 'West Virginia',\n",
    "    'WY': 'Wyoming'\n",
    "    }\n",
    "food_security = food_security.replace({'State': states})\n",
    "\n",
    "#We want to focus on only a few of these columns so we'll subset this dataframe with just the columns we want\n",
    "food_security = food_security[['State','Food Insecurity Rate','Child food insecurity rate', 'Year']]\n",
    "\n",
    "#Save our changes\n",
    "food_security.to_csv('/Users/kayh/Documents/DS4A/team_81_project/To_Data_Studio/food_security.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rates = pd.read_excel('/Users/kayh/Documents/DS4A/Working_Data/Teens ages 16 to 19 not in school and not high school graduates.xlsx')\n",
    "\n",
    "#Rename Headers\n",
    "dropout_rates = dropout_rates.rename(columns = {'Location':'State','TimeFrame':'Year'})\n",
    "\n",
    "#Remove Percents rows & then drop the DataFormat column\n",
    "dropout_rates = dropout_rates[~dropout_rates['DataFormat'].str.contains('Percent')]\n",
    "dropout_rates=dropout_rates.drop('DataFormat',axis=1)\n",
    "\n",
    "#Remove Territories/Nation rows & then remove the LocationType column\n",
    "drop_these = ['Territory','Nation']\n",
    "dropout_rates = dropout_rates[~dropout_rates['LocationType'].isin(drop_these)]\n",
    "dropout_rates = dropout_rates.drop('LocationType', axis=1).reset_index(drop=True)\n",
    "\n",
    "dropout_rates.set_index('State',inplace=True)\n",
    "\n",
    "#Save our changes\n",
    "dropout_rates.to_csv('/Users/kayh/Documents/DS4A/team_81_project/To_Data_Studio/dropoutrates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Year   Data\n",
       "State               \n",
       "Alabama  2019  10000\n",
       "Alabama  2016  10000\n",
       "Alabama  2017  13000\n",
       "Alabama  2012  16000\n",
       "Alabama  2014  14000\n",
       "...       ...    ...\n",
       "Wyoming  2004   2000\n",
       "Wyoming  2003   2000\n",
       "Wyoming  2002   2000\n",
       "Wyoming  2001   3000\n",
       "Wyoming  2000   3000\n",
       "\n",
       "[1020 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Data</th>\n    </tr>\n    <tr>\n      <th>State</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Alabama</th>\n      <td>2019</td>\n      <td>10000</td>\n    </tr>\n    <tr>\n      <th>Alabama</th>\n      <td>2016</td>\n      <td>10000</td>\n    </tr>\n    <tr>\n      <th>Alabama</th>\n      <td>2017</td>\n      <td>13000</td>\n    </tr>\n    <tr>\n      <th>Alabama</th>\n      <td>2012</td>\n      <td>16000</td>\n    </tr>\n    <tr>\n      <th>Alabama</th>\n      <td>2014</td>\n      <td>14000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Wyoming</th>\n      <td>2004</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>Wyoming</th>\n      <td>2003</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>Wyoming</th>\n      <td>2002</td>\n      <td>2000</td>\n    </tr>\n    <tr>\n      <th>Wyoming</th>\n      <td>2001</td>\n      <td>3000</td>\n    </tr>\n    <tr>\n      <th>Wyoming</th>\n      <td>2000</td>\n      <td>3000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1020 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "dropout_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This data was previously found & cleaned by team member: Kaylynne\n",
    "#Additional data cleaning & exploratory analysis by team member: Claudia\n",
    "\n",
    "state_fund = pd.read_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           State  Year  Total Federal Revenue\n",
       "675     Arkansas  2015                   5283\n",
       "676     Arkansas  2015                    269\n",
       "677     Arkansas  2015                   1172\n",
       "678     Arkansas  2015                  27259\n",
       "679     Arkansas  2015                   1655\n",
       "...          ...   ...                    ...\n",
       "117423  Arkansas  2016                    191\n",
       "117424  Arkansas  2016                  12696\n",
       "117425  Arkansas  2016                    659\n",
       "117426  Arkansas  2016                   2587\n",
       "117427  Arkansas  2016                    445\n",
       "\n",
       "[9537 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>Year</th>\n      <th>Total Federal Revenue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>675</th>\n      <td>Arkansas</td>\n      <td>2015</td>\n      <td>5283</td>\n    </tr>\n    <tr>\n      <th>676</th>\n      <td>Arkansas</td>\n      <td>2015</td>\n      <td>269</td>\n    </tr>\n    <tr>\n      <th>677</th>\n      <td>Arkansas</td>\n      <td>2015</td>\n      <td>1172</td>\n    </tr>\n    <tr>\n      <th>678</th>\n      <td>Arkansas</td>\n      <td>2015</td>\n      <td>27259</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <td>Arkansas</td>\n      <td>2015</td>\n      <td>1655</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>117423</th>\n      <td>Arkansas</td>\n      <td>2016</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>117424</th>\n      <td>Arkansas</td>\n      <td>2016</td>\n      <td>12696</td>\n    </tr>\n    <tr>\n      <th>117425</th>\n      <td>Arkansas</td>\n      <td>2016</td>\n      <td>659</td>\n    </tr>\n    <tr>\n      <th>117426</th>\n      <td>Arkansas</td>\n      <td>2016</td>\n      <td>2587</td>\n    </tr>\n    <tr>\n      <th>117427</th>\n      <td>Arkansas</td>\n      <td>2016</td>\n      <td>445</td>\n    </tr>\n  </tbody>\n</table>\n<p>9537 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "#This data was previously found & cleaned by team member: Kaylynne\n",
    "#Additional data cleaning & exploratory analysis by team member: Shayla\n",
    "\n",
    "fed_fund = pd.read_csv('/Users/kayh/Documents/DS4A/team_81_project/Isolated_Metrics/fed_funding.csv')\n",
    "\n",
    "#Drop unnamed column\n",
    "fed_fund = fed_fund.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#Replace STATE Fips with State names\n",
    "fips_states = {2: 'Alaska',\n",
    "    1: 'Alabama',\n",
    "    3: 'American Samoa',\n",
    "    5: 'Arkansas',\n",
    "    4: 'Arizona',\n",
    "    6: 'California',\n",
    "    7: 'Canal Zone',\n",
    "    8: 'Colorado',\n",
    "    9: 'Connecticut',\n",
    "    11: 'District of Columbia',\n",
    "    10: 'Delaware',\n",
    "    12: 'Florida',\n",
    "    13: 'Georgia',\n",
    "    14: 'Guam',\n",
    "    15: 'Hawaii',\n",
    "    19: 'Iowa',\n",
    "    16: 'Idaho',\n",
    "    17: 'Illinois',\n",
    "    18: 'Indiana',\n",
    "    20: 'Kansas',\n",
    "    21: 'Kentucky',\n",
    "    22: 'Louisiana',\n",
    "    25: 'Massachusetts',\n",
    "    24: 'Maryland',\n",
    "    23: 'Maine',\n",
    "    26: 'Michigan',\n",
    "    27: 'Minnesota',\n",
    "    29: 'Missouri',\n",
    "    28: 'Mississippi',\n",
    "    30: 'Montana',\n",
    "    37: 'North Carolina',\n",
    "    38: 'North Dakota',\n",
    "    31: 'Nebraska',\n",
    "    33: 'New Hampshire',\n",
    "    34: 'New Jersey',\n",
    "    35: 'New Mexico',\n",
    "    32: 'Nevada',\n",
    "    36: 'New York',\n",
    "    39: 'Ohio',\n",
    "    40: 'Oklahoma',\n",
    "    41: 'Oregon',\n",
    "    42: 'Pennsylvania',\n",
    "    44: 'Rhode Island',\n",
    "    43: 'Puerto Rico',\n",
    "    45: 'South Carolina',\n",
    "    46: 'South Dakota',\n",
    "    47: 'Tennessee',\n",
    "    48: 'Texas',\n",
    "    49: 'Utah',\n",
    "    51: 'Virginia',\n",
    "    50: 'Vermont',\n",
    "    53: 'Washington',\n",
    "    55: 'Wisconsin',\n",
    "    54: 'West Virginia',\n",
    "    56: 'Wyoming'\n",
    "    }\n",
    "\n",
    "fed_fund = fed_fund.replace({'STATE': fips_states})\n",
    "\n",
    "#Drop STATE rows that are territories\n",
    "fed_fund = fed_fund[~fed_fund['STATE'].str.contains('American Samoa')]\n",
    "fed_fund = fed_fund[~fed_fund['STATE'].str.contains('Canal Zone')]\n",
    "fed_fund = fed_fund[~fed_fund['STATE'].str.contains('Guam')]\n",
    "fed_fund = fed_fund[~fed_fund['STATE'].str.contains('Puerto Rico')]\n",
    "\n",
    "#Replace Year of Data with full YYYY\n",
    "years = {9:2009, 10:2010, 11:2011, 12:2012, 13:2013, 14:2014, 15:2015, 16:2016, 17:2017}\n",
    "fed_fund = fed_fund.replace({'Year of Data': years})\n",
    "\n",
    "#Replace Header Names\n",
    "fed_fund = fed_fund.rename(columns = {'STATE':'State','Year of Data':'Year','Total Revenue from Federal Sources':'Total Federal Revenue'})\n",
    "\n",
    "#Save our changes\n",
    "fed_fund.to_csv('/Users/kayh/Documents/DS4A/team_81_project/To_Data_Studio/fedfund.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This data was previously found & cleaned by team member: Claudia \n",
    "poverty = pd.read_csv('/Users/kayh/Documents/DS4A/team_81_project/Cleaned Datasets/child_poverty.csv')\n",
    "\n",
    "poverty.to_csv('/Users/kayh/Documents/DS4A/team_81_project/To_Data_Studio/childpoverty.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_pay = pd.read_csv('/Users/kayh/Documents/DS4A/team_81_project/Isolated_Metrics/teacher_salary_ests.csv')\n",
    "\n",
    "#Drop all rows with NaN values\n",
    "teacher_pay = teacher_pay.dropna()\n",
    "\n",
    "#We're only pulling 10 years of data here so we can actually drop the first column\n",
    "teacher_pay = teacher_pay.drop('2008-09', axis=1)\n",
    "\n",
    "#Since we're running all these datasets up against each other - we need to make all the dates the same YYYY format\n",
    "teacher_pay = teacher_pay.rename(columns = {'2009-10':'2009','2010-11':'2010','2011-12':'2011','2012-13':'2012','2013-14':'2013','2014-15':'2014','2015-16':'2015','2016-17':'2016','2017-18':'2017','2018-19':'2018'})\n",
    "\n",
    "#We need to get rid of those dots after each state name\n",
    "teacher_pay['State'] = teacher_pay['State'].str.split(' .',expand=True)\n",
    "\n",
    "#We can drop the first row since that row is just totals (and Data Studio isn't a fan)\n",
    "teacher_pay = teacher_pay.iloc[1:]\n",
    "\n",
    "#And we need to add DC's name back into the State column\n",
    "teacher_pay.loc[[11],'State'] = 'District of Columbia'\n",
    "\n",
    "#Save our changes\n",
    "teacher_pay.to_csv('/Users/kayh/Documents/DS4A/team_81_project/To_Data_Studio/TeacherPay.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This data was previously found & cleaned by team member: Claudia \n",
    "teen_employ = pd.read_csv('/Users/kayh/Documents/DS4A/team_81_project/Cleaned Datasets/teen_employment.csv')\n",
    "\n",
    "#Rename Headers for better clarification\n",
    "teen_employ = teen_employ.rename(columns = {'Employed: Total':'Employed per 1k','Employed: Percentage':'% Employed','Unemployed: Total':'Unemployed per 1k', 'Unemployed: Percentage':'% Unemployed'})\n",
    "\n",
    "#Save our changes\n",
    "teen_employ.to_csv('/Users/kayh/Documents/DS4A/team_81_project/To_Data_Studio/teen_employment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This data was previously found & cleaned by team member: Shayla\n",
    "teen_preg = pd.read_csv('/Users/kayh/Documents/DS4A/team_81_project/ds4a81_project/Cleaned Datasets/teen_births_age_15_19.csv')\n",
    "\n",
    "#Remove Unnamed: 0 column (still not sure yet where that's coming from)\n",
    "teen_preg = teen_preg.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#We can also drop the \"Age Group (Years)\" column -- We'll have to be sure to specify it on the presentation/dashboard that this data is specifically looking at students 15-19 years of age.\n",
    "teen_preg = teen_preg.drop('Age Group (Years)', axis=1)\n",
    "\n",
    "#Another column we can drop is the \"Unit\" column. We can note that the rates are per 1k either in the dataframe or in footnotes.\n",
    "teen_preg = teen_preg.drop('Unit', axis=1)\n",
    "\n",
    "#Save our changes\n",
    "teen_preg.to_csv('/Users/kayh/Documents/DS4A/team_81_project/To_Data_Studio/teen_pregnancy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Via: Data Source: U.S. Department of Education, National Center for Education Statistics, Common Core of Data (CCD), \"State Nonfiscal Public Elementary/Secondary Education Survey\", 2016-17 v.1a.\n",
    "\n",
    "#This data was cleaned in the code/cleaned_student_teacher_ratios.ipynb doc so we just need to bring it in.abs\n",
    "\n",
    "all_StuTeach = pd.read_csv('/Users/kayh/Documents/DS4A/team_81_project/To_Data_Studio/Student_Teacher_Ratios.csv')\n",
    "\n",
    "#Remove Unnamed: 0 column (not sure yet where that's coming from)\n",
    "all_StuTeach = all_StuTeach.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#Save our changes\n",
    "all_StuTeach.to_csv('/Users/kayh/Documents/DS4A/team_81_project/To_Data_Studio/Student_Teacher_Ratios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counselors = pd.read_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_edu = pd.read_csv('/Users/kayh/Documents/DS4A/team_81_project/Isolated_Metrics/parent_edu_attain.csv')\n",
    "\n",
    "#Replace state abbreviations with state names\n",
    "states = {'AK': 'Alaska',\n",
    "    'AL': 'Alabama',\n",
    "    'AR': 'Arkansas',\n",
    "    'AZ': 'Arizona',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DC': 'District of Columbia',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'IA': 'Iowa',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MD': 'Maryland',\n",
    "    'ME': 'Maine',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MO': 'Missouri',\n",
    "    'MS': 'Mississippi',\n",
    "    'MT': 'Montana',\n",
    "    'NA': 'National',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'NE': 'Nebraska',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NV': 'Nevada',\n",
    "    'NY': 'New York',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VA': 'Virginia',\n",
    "    'VT': 'Vermont',\n",
    "    'WA': 'Washington',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WV': 'West Virginia',\n",
    "    'WY': 'Wyoming'\n",
    "    }\n",
    "parent_edu = parent_edu.replace({'State': states})\n",
    "\n",
    "#Remove excess rows and NaNs\n",
    "parent_edu = parent_edu.dropna()\n",
    "parent_edu = parent_edu[~parent_edu['State'].str.contains('Total US')]\n",
    "parent_edu = parent_edu[~parent_edu['Educational Attainment'].str.contains('Children under 15')]\n",
    "\n",
    "#Pivot the table so that the Education Attainment column becomes multiple columns\n",
    "parent_edu = pd.pivot_table(parent_edu, index = ['State','Year'], columns='Educational Attainment', values = ['Totals'])\n",
    "\n",
    "#Rename Column Headers\n",
    "parent_edu = parent_edu.rename(columns = {'Bachelor\\'s degree or higher':'Bachelor Degree+','High school or equivalent':'HS Diploma or GED', 'No high school diploma':'No HS Diploma', 'Some college, less than 4-yr degree':'Some College'})\n",
    "\n",
    "#Save our changes\n",
    "parent_edu.to_csv('/Users/kayh/Documents/DS4A/team_81_project/To_Data_Studio/parentedu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}